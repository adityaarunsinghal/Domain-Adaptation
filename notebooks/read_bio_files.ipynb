{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00cbb398e7fa080eddefa05a938b6b2d0bd9fb13bad6d642a712d30be3d64f672",
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2858890bae232c5a2eafb41676f76863dbb689e94c5d0ec3cf4073896e5bad9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import random\n",
    "import json\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to read files and store as nested lists\n",
    "\n",
    "def read_bio(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    data = pd.DataFrame(f, columns=[\"line\"])\n",
    "    f.close()\n",
    "\n",
    "    breaks = [0]\n",
    "    breaks.extend(list(data[data.line==\"\\n\"].index))\n",
    "    labels = {}\n",
    "    tokens = {}\n",
    "    for i in range(len(breaks)-1):\n",
    "        # print(i)\n",
    "        labels[i] = []\n",
    "        tokens[i] = []\n",
    "        for j in range(breaks[i]+1, breaks[i+1]):\n",
    "            line = data.loc[j, \"line\"]\n",
    "            tokens[i].append(line.split(\"\\t\")[1][:-1])\n",
    "            labels[i].append(line.split(\"\\t\")[0])\n",
    "\n",
    "    return (list(tokens.values()), list(labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_bio(\"../datasets/movies/MIT_movie_NER/original_files/engtrain.bio\")\n",
    "X_test, y_test = read_bio(\"../datasets/movies/MIT_movie_NER/original_files/engtest.bio\")\n",
    "trivia_X, trivia_y = read_bio(\"../datasets/movies/MIT_movie_NER/original_files/trivia10k13train.bio\")\n",
    "trivia_X_test, trivia_y_test = read_bio(\"../datasets/movies/MIT_movie_NER/original_files/trivia10k13test.bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "trivia_X, trivia_y = shuffle(trivia_X, trivia_y, random_state=0)\n",
    "trivia_X_test, trivia_y_test = shuffle(trivia_X_test, trivia_y_test, random_state=0)\n",
    "\n",
    "val_cutoff = round(0.2*len(X))\n",
    "X_val = X[:val_cutoff]\n",
    "X_train = X[val_cutoff:]\n",
    "y_val = y[:val_cutoff]\n",
    "y_train = y[val_cutoff:]\n",
    "\n",
    "# random.shuffle(trivia_X)\n",
    "\n",
    "trivia_val_cutoff = round(0.2*len(trivia_X))\n",
    "trivia_X_val = trivia_X[:trivia_val_cutoff]\n",
    "trivia_X_train = trivia_X[trivia_val_cutoff:]\n",
    "trivia_y_val = trivia_y[:trivia_val_cutoff]\n",
    "trivia_y_train = trivia_y[trivia_val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../datasets/movies/MIT_movie_NER/nested_lists/trivia_y_val']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "joblib.dump(X_train, \"../datasets/movies/MIT_movie_NER/nested_lists/X_train\")\n",
    "joblib.dump(y_train, \"../datasets/movies/MIT_movie_NER/nested_lists/y_train\")\n",
    "joblib.dump(X_test, \"../datasets/movies/MIT_movie_NER/nested_lists/X_test\")\n",
    "joblib.dump(y_test, \"../datasets/movies/MIT_movie_NER/nested_lists/y_test\")\n",
    "joblib.dump(X_val, \"../datasets/movies/MIT_movie_NER/nested_lists/X_val\")\n",
    "joblib.dump(y_val, \"../datasets/movies/MIT_movie_NER/nested_lists/y_val\")\n",
    "joblib.dump(trivia_X_train, \"../datasets/movies/MIT_movie_NER/nested_lists/trivia_X_train\")\n",
    "joblib.dump(trivia_y_train, \"../datasets/movies/MIT_movie_NER/nested_lists/trivia_y_train\")\n",
    "joblib.dump(trivia_X_test, \"../datasets/movies/MIT_movie_NER/nested_lists/trivia_X_test\")\n",
    "joblib.dump(trivia_y_test, \"../datasets/movies/MIT_movie_NER/nested_lists/trivia_y_test\")\n",
    "joblib.dump(trivia_X_val, \"../datasets/movies/MIT_movie_NER/nested_lists/trivia_X_val\")\n",
    "joblib.dump(trivia_y_val, \"../datasets/movies/MIT_movie_NER/nested_lists/trivia_y_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../datasets/movies/MIT_movie_NER/dict_structure/testing.dict']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "training = {}\n",
    "validation = {}\n",
    "testing = {}\n",
    "trivia_training = {}\n",
    "trivia_validation = {}\n",
    "trivia_testing = {}\n",
    "\n",
    "trivia_training['sentences'] = trivia_X_train\n",
    "trivia_training['tags'] = trivia_y_train\n",
    "trivia_validation['sentences'] = trivia_X_val\n",
    "trivia_validation['tags'] = trivia_y_val\n",
    "trivia_testing['sentences'] = trivia_X_test\n",
    "trivia_testing['tags'] = trivia_y_test\n",
    "\n",
    "training['sentences'] = X_train\n",
    "training['tags'] = y_train\n",
    "validation['sentences'] = X_val\n",
    "validation['tags'] = y_val\n",
    "testing['sentences'] = X_test\n",
    "testing['tags'] = y_test\n",
    "\n",
    "\n",
    "joblib.dump(trivia_training, \"../datasets/movies/MIT_movie_NER/dict_structure/trivia_training.dict\")\n",
    "joblib.dump(trivia_validation, \"../datasets/movies/MIT_movie_NER/dict_structure/trivia_validation.dict\")\n",
    "joblib.dump(trivia_testing, \"../datasets/movies/MIT_movie_NER/dict_structure/trivia_testing.dict\")\n",
    "joblib.dump(training, \"../datasets/movies/MIT_movie_NER/dict_structure/training.dict\")\n",
    "joblib.dump(validation, \"../datasets/movies/MIT_movie_NER/dict_structure/validation.dict\")\n",
    "joblib.dump(testing, \"../datasets/movies/MIT_movie_NER/dict_structure/testing.dict\")"
   ]
  },
  {
   "source": [
    "## Checking the different possible BIO tags we have"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal NER\n",
    "\n",
    "train_tag_scheme = []\n",
    "for each_list in y_train:\n",
    "    for each in set(each_list):\n",
    "        if each not in train_tag_scheme:\n",
    "            train_tag_scheme.append(each)\n",
    "\n",
    "train_tag_scheme.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-ACTOR',\n",
       " 'B-CHARACTER',\n",
       " 'B-DIRECTOR',\n",
       " 'B-GENRE',\n",
       " 'B-PLOT',\n",
       " 'B-RATING',\n",
       " 'B-RATINGS_AVERAGE',\n",
       " 'B-REVIEW',\n",
       " 'B-SONG',\n",
       " 'B-TITLE',\n",
       " 'B-TRAILER',\n",
       " 'B-YEAR',\n",
       " 'I-ACTOR',\n",
       " 'I-CHARACTER',\n",
       " 'I-DIRECTOR',\n",
       " 'I-GENRE',\n",
       " 'I-PLOT',\n",
       " 'I-RATING',\n",
       " 'I-RATINGS_AVERAGE',\n",
       " 'I-REVIEW',\n",
       " 'I-SONG',\n",
       " 'I-TITLE',\n",
       " 'I-TRAILER',\n",
       " 'I-YEAR',\n",
       " 'O']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train_tag_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trivia NER\n",
    "\n",
    "trivia_tag_scheme = []\n",
    "for each_list in trivia_y_train:\n",
    "    for each in set(each_list):\n",
    "        if each not in trivia_tag_scheme:\n",
    "            trivia_tag_scheme.append(each)\n",
    "            \n",
    "trivia_tag_scheme.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-Actor',\n",
       " 'B-Award',\n",
       " 'B-Character_Name',\n",
       " 'B-Director',\n",
       " 'B-Genre',\n",
       " 'B-Opinion',\n",
       " 'B-Origin',\n",
       " 'B-Plot',\n",
       " 'B-Quote',\n",
       " 'B-Relationship',\n",
       " 'B-Soundtrack',\n",
       " 'B-Year',\n",
       " 'I-Actor',\n",
       " 'I-Award',\n",
       " 'I-Character_Name',\n",
       " 'I-Director',\n",
       " 'I-Genre',\n",
       " 'I-Opinion',\n",
       " 'I-Origin',\n",
       " 'I-Plot',\n",
       " 'I-Quote',\n",
       " 'I-Relationship',\n",
       " 'I-Soundtrack',\n",
       " 'I-Year',\n",
       " 'O']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "trivia_tag_scheme"
   ]
  }
 ]
}