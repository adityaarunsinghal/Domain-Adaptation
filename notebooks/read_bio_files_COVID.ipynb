{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00cbb398e7fa080eddefa05a938b6b2d0bd9fb13bad6d642a712d30be3d64f672",
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2858890bae232c5a2eafb41676f76863dbb689e94c5d0ec3cf4073896e5bad9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import random\n",
    "import json\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to read files and store as nested lists\n",
    "\n",
    "def read_bio(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    data = pd.DataFrame(f, columns=[\"line\"])\n",
    "    f.close()\n",
    "\n",
    "    breaks = [0]\n",
    "    breaks.extend(list(data[data.line==\"\\n\"].index))\n",
    "    labels = {}\n",
    "    tokens = {}\n",
    "    for i in range(len(breaks)-1):\n",
    "        # print(i)\n",
    "        labels[i] = []\n",
    "        tokens[i] = []\n",
    "        for j in range(breaks[i]+1, breaks[i+1]):\n",
    "            line = data.loc[j, \"line\"]\n",
    "            tokens[i].append(line.split(\"\\t\")[1][:-1])\n",
    "            labels[i].append(line.split(\"\\t\")[0])\n",
    "\n",
    "    return (list(tokens.values()), list(labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_bio(\"../datasets/covid/train.txt\")\n",
    "X_test, y_test = read_bio(\"../datasets/covid/test.txt\")\n",
    "X_dev, y_dev = read_bio(\"../datasets/covid/devel.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../datasets/covid/y_dev']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "joblib.dump(X_train, \"../datasets/covid/X_train\")\n",
    "joblib.dump(y_train, \"../datasets/covid/y_train\")\n",
    "joblib.dump(X_test, \"../datasets/covid/X_test\")\n",
    "joblib.dump(y_test, \"../datasets/covid/y_test\")\n",
    "joblib.dump(X_dev, \"../datasets/covid/X_dev\")\n",
    "joblib.dump(y_dev, \"../datasets/covid/y_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../datasets/movies/MIT_movie_NER/dict_structure/testing.dict']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "training = {}\n",
    "validation = {}\n",
    "testing = {}\n",
    "\n",
    "training['sentences'] = X_train\n",
    "training['tags'] = y_train\n",
    "validation['sentences'] = X_val\n",
    "validation['tags'] = y_val\n",
    "testing['sentences'] = X_test\n",
    "testing['tags'] = y_test\n",
    "\n",
    "\n",
    "joblib.dump(trivia_training, \"../datasets/movies/MIT_movie_NER/dict_structure/trivia_training.dict\")\n",
    "joblib.dump(trivia_validation, \"../datasets/movies/MIT_movie_NER/dict_structure/trivia_validation.dict\")\n",
    "joblib.dump(trivia_testing, \"../datasets/movies/MIT_movie_NER/dict_structure/trivia_testing.dict\")\n",
    "joblib.dump(training, \"../datasets/movies/MIT_movie_NER/dict_structure/training.dict\")\n",
    "joblib.dump(validation, \"../datasets/movies/MIT_movie_NER/dict_structure/validation.dict\")\n",
    "joblib.dump(testing, \"../datasets/movies/MIT_movie_NER/dict_structure/testing.dict\")"
   ]
  },
  {
   "source": [
    "## Checking the different possible BIO tags we have"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-692b92ce9a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tag_scheme\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mtrain_tag_scheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normal NER\n",
    "\n",
    "train_tag_scheme = []\n",
    "for each_list in y_train:\n",
    "    for each in set(each_list):\n",
    "        if each not in train_tag_scheme:\n",
    "            train_tag_scheme.append(each)\n",
    "\n",
    "train_tag_scheme.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_scheme"
   ]
  }
 ]
}