2021-04-21 02:19:54.086517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Reusing dataset squad (/home/as11919/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)
[INFO|configuration_utils.py:488] 2021-04-21 02:19:56,427 >> loading configuration file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/config.json
[INFO|configuration_utils.py:526] 2021-04-21 02:19:56,427 >> Model config RobertaConfig {
  "_name_or_path": "/scratch/as11919/Domain-Adaptation/movie_roberta/movie_roberta_15April2021/checkpoint-100000",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|configuration_utils.py:488] 2021-04-21 02:19:56,427 >> loading configuration file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/config.json
[INFO|configuration_utils.py:526] 2021-04-21 02:19:56,427 >> Model config RobertaConfig {
  "_name_or_path": "/scratch/as11919/Domain-Adaptation/movie_roberta/movie_roberta_15April2021/checkpoint-100000",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1647] 2021-04-21 02:19:56,428 >> Didn't find file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/tokenizer.json. We won't load it.
[INFO|tokenization_utils_base.py:1647] 2021-04-21 02:19:56,428 >> Didn't find file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1711] 2021-04-21 02:19:56,428 >> loading file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/vocab.json
[INFO|tokenization_utils_base.py:1711] 2021-04-21 02:19:56,428 >> loading file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/merges.txt
[INFO|tokenization_utils_base.py:1711] 2021-04-21 02:19:56,428 >> loading file None
[INFO|tokenization_utils_base.py:1711] 2021-04-21 02:19:56,429 >> loading file None
[INFO|tokenization_utils_base.py:1711] 2021-04-21 02:19:56,429 >> loading file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/special_tokens_map.json
[INFO|tokenization_utils_base.py:1711] 2021-04-21 02:19:56,429 >> loading file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/tokenizer_config.json
[INFO|modeling_utils.py:1050] 2021-04-21 02:19:56,574 >> loading weights file /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021/pytorch_model.bin
[WARNING|modeling_utils.py:1159] 2021-04-21 02:20:00,612 >> Some weights of the model checkpoint at /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021 were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']
- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1170] 2021-04-21 02:20:00,613 >> Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at /scratch/as11919/Domain-Adaptation/models/movie_roberta/movie_roberta_15April2021 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/88 [00:00<?, ?ba/s]  1%|          | 1/88 [00:00<00:26,  3.25ba/s]  2%|▏         | 2/88 [00:00<00:24,  3.48ba/s]  3%|▎         | 3/88 [00:00<00:27,  3.04ba/s]  5%|▍         | 4/88 [00:01<00:24,  3.39ba/s]  6%|▌         | 5/88 [00:01<00:22,  3.64ba/s]  7%|▋         | 6/88 [00:01<00:21,  3.85ba/s]  8%|▊         | 7/88 [00:01<00:20,  4.02ba/s]  9%|▉         | 8/88 [00:02<00:19,  4.20ba/s] 10%|█         | 9/88 [00:02<00:21,  3.69ba/s] 11%|█▏        | 10/88 [00:02<00:19,  3.92ba/s] 12%|█▎        | 11/88 [00:02<00:18,  4.14ba/s] 14%|█▎        | 12/88 [00:03<00:17,  4.27ba/s] 15%|█▍        | 13/88 [00:03<00:17,  4.39ba/s] 16%|█▌        | 14/88 [00:03<00:16,  4.47ba/s] 17%|█▋        | 15/88 [00:03<00:15,  4.57ba/s] 18%|█▊        | 16/88 [00:03<00:17,  4.15ba/s] 19%|█▉        | 17/88 [00:04<00:16,  4.31ba/s] 20%|██        | 18/88 [00:04<00:15,  4.47ba/s] 22%|██▏       | 19/88 [00:04<00:15,  4.49ba/s] 23%|██▎       | 20/88 [00:04<00:14,  4.55ba/s] 24%|██▍       | 21/88 [00:05<00:14,  4.56ba/s] 25%|██▌       | 22/88 [00:05<00:16,  4.10ba/s] 26%|██▌       | 23/88 [00:05<00:15,  4.25ba/s] 27%|██▋       | 24/88 [00:05<00:15,  4.25ba/s] 28%|██▊       | 25/88 [00:06<00:14,  4.40ba/s] 30%|██▉       | 26/88 [00:06<00:13,  4.47ba/s] 31%|███       | 27/88 [00:06<00:13,  4.38ba/s] 32%|███▏      | 28/88 [00:06<00:16,  3.68ba/s] 33%|███▎      | 29/88 [00:07<00:15,  3.83ba/s] 34%|███▍      | 30/88 [00:07<00:14,  3.90ba/s] 35%|███▌      | 31/88 [00:07<00:14,  3.97ba/s] 36%|███▋      | 32/88 [00:07<00:14,  3.94ba/s] 38%|███▊      | 33/88 [00:08<00:13,  4.03ba/s] 39%|███▊      | 34/88 [00:08<00:14,  3.68ba/s] 40%|███▉      | 35/88 [00:08<00:13,  3.85ba/s] 41%|████      | 36/88 [00:08<00:13,  3.91ba/s] 42%|████▏     | 37/88 [00:09<00:12,  4.02ba/s] 43%|████▎     | 38/88 [00:09<00:12,  4.10ba/s] 44%|████▍     | 39/88 [00:09<00:12,  4.06ba/s] 45%|████▌     | 40/88 [00:09<00:13,  3.56ba/s] 47%|████▋     | 41/88 [00:10<00:12,  3.75ba/s] 48%|████▊     | 42/88 [00:10<00:11,  3.90ba/s] 49%|████▉     | 43/88 [00:10<00:11,  4.03ba/s] 50%|█████     | 44/88 [00:10<00:10,  4.14ba/s] 51%|█████     | 45/88 [00:11<00:10,  4.18ba/s] 52%|█████▏    | 46/88 [00:11<00:11,  3.70ba/s] 53%|█████▎    | 47/88 [00:11<00:10,  3.83ba/s] 55%|█████▍    | 48/88 [00:11<00:10,  3.99ba/s] 56%|█████▌    | 49/88 [00:12<00:09,  4.07ba/s] 57%|█████▋    | 50/88 [00:12<00:09,  4.12ba/s] 58%|█████▊    | 51/88 [00:12<00:08,  4.13ba/s] 59%|█████▉    | 52/88 [00:13<00:10,  3.51ba/s] 60%|██████    | 53/88 [00:13<00:09,  3.71ba/s] 61%|██████▏   | 54/88 [00:13<00:08,  3.87ba/s] 62%|██████▎   | 55/88 [00:13<00:08,  3.94ba/s] 64%|██████▎   | 56/88 [00:13<00:07,  4.02ba/s] 65%|██████▍   | 57/88 [00:14<00:07,  4.07ba/s] 66%|██████▌   | 58/88 [00:14<00:08,  3.64ba/s] 67%|██████▋   | 59/88 [00:14<00:07,  3.79ba/s] 68%|██████▊   | 60/88 [00:15<00:07,  3.93ba/s] 69%|██████▉   | 61/88 [00:15<00:06,  4.03ba/s] 70%|███████   | 62/88 [00:15<00:06,  4.07ba/s] 72%|███████▏  | 63/88 [00:15<00:06,  4.13ba/s] 73%|███████▎  | 64/88 [00:15<00:05,  4.18ba/s] 74%|███████▍  | 65/88 [00:16<00:06,  3.70ba/s] 75%|███████▌  | 66/88 [00:16<00:05,  3.79ba/s] 76%|███████▌  | 67/88 [00:16<00:05,  3.93ba/s] 77%|███████▋  | 68/88 [00:17<00:04,  4.04ba/s] 78%|███████▊  | 69/88 [00:17<00:04,  4.09ba/s] 80%|███████▉  | 70/88 [00:17<00:04,  4.11ba/s] 81%|████████  | 71/88 [00:17<00:04,  3.70ba/s] 82%|████████▏ | 72/88 [00:18<00:04,  3.83ba/s] 83%|████████▎ | 73/88 [00:18<00:03,  3.96ba/s] 84%|████████▍ | 74/88 [00:18<00:03,  4.04ba/s] 85%|████████▌ | 75/88 [00:18<00:03,  4.13ba/s] 86%|████████▋ | 76/88 [00:18<00:02,  4.14ba/s] 88%|████████▊ | 77/88 [00:19<00:02,  3.76ba/s] 89%|████████▊ | 78/88 [00:19<00:02,  3.91ba/s] 90%|████████▉ | 79/88 [00:19<00:02,  3.88ba/s] 91%|█████████ | 80/88 [00:20<00:02,  3.98ba/s] 92%|█████████▏| 81/88 [00:20<00:01,  4.10ba/s] 93%|█████████▎| 82/88 [00:20<00:01,  4.15ba/s] 94%|█████████▍| 83/88 [00:20<00:01,  3.61ba/s] 95%|█████████▌| 84/88 [00:21<00:01,  3.78ba/s] 97%|█████████▋| 85/88 [00:21<00:00,  3.92ba/s] 98%|█████████▊| 86/88 [00:21<00:00,  4.04ba/s] 99%|█████████▉| 87/88 [00:21<00:00,  4.13ba/s]100%|██████████| 88/88 [00:21<00:00,  4.72ba/s]100%|██████████| 88/88 [00:21<00:00,  4.01ba/s]
  0%|          | 0/11 [00:00<?, ?ba/s]  9%|▉         | 1/11 [00:01<00:10,  1.00s/ba] 18%|█▊        | 2/11 [00:01<00:08,  1.02ba/s] 27%|██▋       | 3/11 [00:02<00:07,  1.09ba/s] 36%|███▋      | 4/11 [00:03<00:06,  1.08ba/s] 45%|████▌     | 5/11 [00:04<00:05,  1.02ba/s] 55%|█████▍    | 6/11 [00:05<00:04,  1.02ba/s] 64%|██████▎   | 7/11 [00:06<00:03,  1.03ba/s] 73%|███████▎  | 8/11 [00:07<00:02,  1.03ba/s] 82%|████████▏ | 9/11 [00:08<00:01,  1.03ba/s] 91%|█████████ | 10/11 [00:09<00:00,  1.09ba/s]100%|██████████| 11/11 [00:09<00:00,  1.25ba/s]100%|██████████| 11/11 [00:09<00:00,  1.11ba/s]
Traceback (most recent call last):
  File "/scratch/as11919/transformers/examples/question-answering/run_qa.py", line 609, in <module>
    main()
  File "/scratch/as11919/transformers/examples/question-answering/run_qa.py", line 488, in main
    raise ValueError("--do_predict requires a test dataset")
ValueError: --do_predict requires a test dataset
